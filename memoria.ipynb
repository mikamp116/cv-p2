{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta práctica está compuesta por tres apartados, en los que se deben localizar y reconocer caracteres de matrículas de\n",
    "coches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1: Localización de los caracteres de la matrícula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este apartado aparece desarrollado en los ficheros *localizacion_caracteres.py*, *localizacion_matricula* y \n",
    "*deteccion_haar.py*.\n",
    "\n",
    "En el fichero *deteccion_haar.py* se desarrolla la clase *HaarDetector*, que recibe un fichero XML para entrenar un \n",
    "clasificador en cascada que servirá para localizar la posición de la matricula de los coches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa la libreria a utilizar, OpenCV, y se define la clase *HaarDetector*. El contructor de esta clase recibe un \n",
    "parámetro obligatorio y dos opcionales:\n",
    "\n",
    "- **classifier_file**: el archivo XML necesario para entrenar el clasificador en cascada. Dependiendo del archivo xml el\n",
    "clasificador detectará unas regiones u otras.\n",
    "- **scale_factor**: el factor de escala entre las imágenes generadas por el clasificador. Es opcional, si no se \n",
    "introduce, su valor por defecto es 1.3.\n",
    "- **min_neighbors**: el número mínimo de vecinos que debe tener una región candidata para ser válida. Es opcional, si no \n",
    "se introduce, su valor por defecto es 5.\n",
    "\n",
    "En el constructor se crea y entrena un clasificador denominado *classifier* pasando el fichero obtenido al método \n",
    "`cv.CascadeClassifier()`. Los otros dos valores se almacenan en la clase y se podrán obtener mediante los métodos \n",
    "`get_scale_factor()` y `get_min_neighbors()` y cambiar mediante los métodos `set_scale_factor()` y `set_min_neighbors()`\n",
    ", respectivamente. Los dos últimos métodos reciben como parámetro el nuevo valor del atributo.\n",
    "\n",
    "El método `detect()` recibe una lista de imágenes y, de nuevo opcionalmente, el factor de escala y el mínimo número de \n",
    "vecinos. Si no se especifica el valor de estos parámetros, lo obtiene de los atributos almacenado en la clase. El método \n",
    "devuelve una lista de arrays de *Numpy*, uno por cada imagen de la lista, con las coordenadas $x$ e $y$ de la esquina \n",
    "superior derecha, la altura y la anchura de la región, o regiones, detectadas por el clasificador. El array de *Numpy* \n",
    "tendrá 4 columnas, una por cada uno de estos datos, y una fila por cada región detectada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "\n",
    "class HaarDetector:\n",
    "    def __init__(self, classifier_file, scale_factor=1.3, min_neighbors=5):\n",
    "        self.classifier = cv.CascadeClassifier(classifier_file)\n",
    "        self.scale_factor = scale_factor\n",
    "        self.min_neighbors = min_neighbors\n",
    "\n",
    "    def get_scale_factor(self):\n",
    "        return self.scale_factor\n",
    "\n",
    "    def set_scale_factor(self, scale_factor):\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def get_min_neighbors(self):\n",
    "        return self.min_neighbors\n",
    "\n",
    "    def set_min_neighbors(self, min_neighbors):\n",
    "        self.min_neighbors = min_neighbors\n",
    "\n",
    "    def detect(self, images, scale_factor=None, min_neighbors=None):\n",
    "        if scale_factor is None:\n",
    "            scale_factor = self.scale_factor\n",
    "        if min_neighbors is None:\n",
    "            min_neighbors = self.min_neighbors\n",
    "        return [self.classifier.detectMultiScale(image, scale_factor, min_neighbors) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se documenta el fichero *localizacion_matricula.py*\n",
    "\n",
    "El detector de matrículas haar funciona en las imágenes en las que el coche está en posición frontal, pero si el coche está ligeramente girado, puede no funcionar. Por eso hemos implementado otro detector de matrículas, este basado en componentes conexas de una imagen umbralizada para encontrar un rectángulo blanco: la matrícula. Este detector está implementado en el fichero *localizacion_matricula.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método *buscar_matricula* recibe una imagen en escala de grises y un detector de coches orb junto a un emparejador de descriptores y un objeto FLANN. Este detector orb se corresponde con el desarrollado en la práctica 1, y detecta el coche que se encuentra en la imagen proporcionada.\n",
    "\n",
    "A partir del punto obtenido como centro del coche, buscamos rectángulos candidatos a matrícula con el método *get_possible_plates()*. Después, buscamos rectángulos candidatos a carácteres dentro de esas posibles matrículas, y supondremos que la verdadera matrícula es la que más carácteres contiene (la variable plate_index guarda el índice de la matrícula elegida). Si hemos encontrado pocos carácteres (menos de 4), volveremos a buscar posibles matrículas pero aplicando ahora un erosionado en la imagen umbralizada para salvar algún pequeño error en la búsqueda anterior. Cuando encontramos un candidato a matrícula robusto, devolvemos un numpy array con las dimensiones de la matrícula (posición en x, posición en y, anchura y altura)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def buscar_matricula(image, orb, match_table, flann):\n",
    "    detected_points = deteccion_orb.detect([image], orb, match_table, flann, 4, 2, 1)\n",
    "    centre = detected_points[0]\n",
    "    rect_plates, box_plates = get_possible_plates(image, centre)\n",
    "    numbers, plate_index = find_numbers_in_plates(image, rect_plates, rotated_plate=True)\n",
    "    for j in range(2, 5):\n",
    "        if len(numbers) < 4:\n",
    "            rect_plates, box_plates = get_possible_plates(image, centre, erode=True, esize=j)\n",
    "            numbers, plate_index = find_numbers_in_plates(image, rect_plates, rotated_plate=True)\n",
    "    rect_plate = rect_plates[plate_index]\n",
    "    return rect_plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método *get_possible_plates()* recibe una imagen en escala de grises y la posición del coche. También se puede elegir si se va a realizar el erosionado y con qué tamaño de kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_possible_plates(img, car_position, erode=False, esize=3):\n",
    "    threshold = umbralizado(img,blur=True, tipo=3, ksize=11, c=2)\n",
    "    plates = []\n",
    "    rect_plates, box_plates = find_plate_contours(threshold, car_position)\n",
    "\n",
    "    if len(plates) == 0 or erode:\n",
    "        kernel = np.ones((esize, esize), np.uint8)\n",
    "        eroded_img = cv2.erode(threshold, kernel, iterations=1)\n",
    "        rect_plates, box_plates = find_plate_contours(eroded_img, car_position)\n",
    "\n",
    "    return rect_plates, box_plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método *find_plate_contours()* recibe una imagen binaria y la posición del coche en la imagen, busca rectángulos que puedan corresponderse con una matrícula y devuelve cada uno de ellos de dos formas, como el rectángulo con ejes paralelos a los de la imagen y como el rectángulo mínimo que contiene la matrícula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_plate_contours(binary_img, car_position):\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    plate_rect = []\n",
    "    plate_box = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 9:\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            x, y, w, h = get_box_size(rect)\n",
    "            x_p, y_p, w_p, h_p = cv2.boundingRect(cnt)\n",
    "            if possible_plate(car_position, (x, y, w, h)):\n",
    "                plate_rect.append([x_p,y_p,w_p,h_p])\n",
    "                plate_box.append(box)\n",
    "\n",
    "    return plate_rect, plate_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes métodos nos permiten seleccionar un rectángulo como matrícula siempre que esté a una distancia no muy lejana del centro del coche y la relación de aspecto del rectángulo mínimo sea más o menos la de una matrícula española."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def possible_plate(car_pos, rect_dim):\n",
    "    return possible_plate_position(car_pos[0], car_pos[1], rect_dim[0], rect_dim[1]+rect_dim[3]/2) \\\n",
    "           and minimum_plate_size(rect_dim[2], rect_dim[3])\n",
    "\n",
    "def possible_plate_position(car_x, car_y, rect_x, rect_y):\n",
    "    return -150 < (car_x - rect_x) < 100 and -50 < (rect_y - car_y) < 200\n",
    "\n",
    "def minimum_plate_size(width, height):\n",
    "    return width > 40 and height > 9 and 4.2 < width/height < 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, el método *find_numbers_in_plates()* recibe una imagen en escala de grises, una lista con las posibles matrículas encontradas en esta imagen y un booleano que indica si la matrícula es paralela a los ejes de la imagen o no. Esto nos sirve para determinar el ratio anchura/altura de los carácteres ya que al estar la matrícula rotada los carácteres serán más alargados.\n",
    "\n",
    "Por cada candidato a matrícula buscamos carácteres dentro y elegimos el candidato que más carácteres tenga. Devolvemos una lista con los carácteres encontrados en ese candidato y el índice del candidato en el array de matrículas para esta imagen.\n",
    "\n",
    "Para buscar los carácteres utilizamos en método *findContours()* de openCV sobre la imagen de la matrícula recortada y umbralizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_numbers_in_plates(img, possible_plates, rotated_plate=False):\n",
    "    possible_plates = np.array(possible_plates)\n",
    "    total_chars = []\n",
    "    chars_found = []\n",
    "    min_wh_ratio = 1.5 if rotated_plate else 1\n",
    "    max_wh_ratio = 6 if rotated_plate else 5\n",
    "\n",
    "    for plate in possible_plates:\n",
    "        chars_in_plate = []\n",
    "        plate_img = img[plate[1]:plate[1] + plate[3], plate[0]:plate[0] + plate[2]]\n",
    "        thresh_img = umbralizado(plate_img, blur=True)\n",
    "        contours, _ = cv2.findContours(thresh_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 15:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                if min_wh_ratio < h/w < max_wh_ratio:\n",
    "                    chars_in_plate.append((x,y,w,h))\n",
    "        chars_in_plate = get_external_rectangles(chars_in_plate)\n",
    "\n",
    "        chars_found.append(len(chars_in_plate))\n",
    "        total_chars.append(chars_in_plate)\n",
    "\n",
    "    if len(chars_found) > 0:\n",
    "        most_chars_plate_index = np.argmax(chars_found)\n",
    "        chars_in_plate = total_chars[most_chars_plate_index]\n",
    "\n",
    "    else:\n",
    "        chars_in_plate = []\n",
    "        most_chars_plate_index = 0\n",
    "\n",
    "\n",
    "    return chars_in_plate, most_chars_plate_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "El fichero *localizacion_caracteres.py* está dedicado a la localización de los caracteres de las matrículas de los \n",
    "coches.\n",
    "\n",
    "El método *load()* recibe como parámetros el directorio del que cargar las imágenes, una lista con los caracteres a \n",
    "excluir y una variable que especifica si las \n",
    "imágenes deben ser cargadas a color o en niveles de grises. Calcula el directorio actual por si este es relativo y, en \n",
    "caso de que lo sea, crea la ruta absoluta. Busca todos los ficheros que se encuentran en el directorio especificado e \n",
    "inserta en una lista aquellos que deben incluirse. La lista se ordena y se devuelve otra lista conteniendo las imágenes \n",
    "cargadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load(directory, color=False, exclude=None):\n",
    "    \"\"\"Devuelve una lista con las imagenes en color o escala de grises contenidas en el directorio pasado como argumento\n",
    "    descartando aquellas imagenes cuya primera letra este en la lista de excluidos\"\"\"\n",
    "    if exclude is None:\n",
    "        exclude = ['.']\n",
    "    cur_dir = os.path.abspath(os.curdir)\n",
    "    if directory.startswith(\"/\"):\n",
    "        path = directory\n",
    "    else:\n",
    "        path = cur_dir + '/' + directory\n",
    "    with os.scandir(path) as it:\n",
    "        files = [file.name for file in it if file.name[0] not in exclude and file.is_file()]\n",
    "    it.close()\n",
    "    files.sort()\n",
    "    if color is True:\n",
    "        return [cv.imread(directory + '/' + file) for file in files], files\n",
    "    else:\n",
    "        return [cv.imread(directory + '/' + file, 0) for file in files], files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La función *umbralizado()* recibe una lista de imágenes y el tipo de umbralizado. El tipo 0 es el umbralizado \n",
    "adaptativo y este requiere dos parámetros especiales, pasados también como parámetro de la función *umbralizado()*. El \n",
    "tipo 1 es el umbralizado binario y, el tipo 2, el de Otsu. Además, se puede decidir si se quiere aplicar un \n",
    "suavizado a la imagen antes de umbralizar. Se aplica el umbralizado especificado a cada imagen de la lista y se \n",
    "devuelven umbralizadas dentro de una lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "def umbralizado(images, blur=False, tipo=0, ksize=5, c=2):\n",
    "    \"\"\"Devuelve una lista de imagenes umbralizadas mediante el tipo de umbralizado especificado en los parámetros\"\"\"\n",
    "    imagenes_umbralizadas = []\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "\n",
    "        if blur is True:\n",
    "            image = cv.GaussianBlur(image, (3, 7), 0)\n",
    "\n",
    "        if tipo == 0:\n",
    "            th = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, ksize, c)\n",
    "        elif tipo == 1:\n",
    "            _, th = cv.threshold(image, 127, 255, cv.THRESH_BINARY)\n",
    "        else:\n",
    "            _, th = cv.threshold(image, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "        imagenes_umbralizadas.append(th)\n",
    "\n",
    "    return imagenes_umbralizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "la función *negativo()* recibe una lista de listas con imágenes umbralizadas y devuelve estas imágenes invertidas, \n",
    "conservando la estructura de listas anidadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def negativo(images):\n",
    "    images_negativo = []\n",
    "    for image_list in images:\n",
    "        aux = []\n",
    "        for image in image_list:\n",
    "            aux.append(cv.bitwise_not(image))\n",
    "        images_negativo.append(aux)\n",
    "\n",
    "    return images_negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "El siguiente método hace uso de la clase *HaarDetector* para localizar las coordenadas en las que se encuentran las \n",
    "matrículas de cada imagen, devolviendo una lista de Numpy arrays con 4 columnas (coordenada x, y, anchura y altura) y \n",
    "con tantas filas como matriculas haya detectado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_contorno_matricula_haar(input_images):\n",
    "    \"\"\"Devuelve una lista con la posion de la matricula\"\"\"\n",
    "    clasificador_matriculas = haardet.HaarDetector('haar_opencv_4.1-4.2/matriculas.xml')\n",
    "    return clasificador_matriculas.detect(input_images, 1.1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función principal del método, *localizar()*, se encarga de la localización de los caracteres haciendo uso de los \n",
    "métodos antes descritos, además de otros implementados en otros ficheros.\n",
    "\n",
    "Comienza cargando todas las imágenes del directorio en niveles de gris y en blanco y negro. Las imágenes en niveles de \n",
    "gris se utilizarán para la detección de caracteres mediante el clasificador haar de la clase *HaarDetector*. Las \n",
    "coordenadas de matrículas detectadas se almacenan en la variable *matriculas*. Sin embargo, el detector haar no detecta \n",
    "todas las matrículas, no es capaz de detectar las que no están de frente a la cámara. Es por ello que se recorre la \n",
    "lista de matrículas detectadas y se vuelve a detectar para las imágenes en las que el haar no fue útil. Esta segunda \n",
    "detección se hace mediante un detector ORB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def localizar(directory):\n",
    "    # Imagenes sobre las que detectar en escala de grises. Por cada imagen hay una lista con un elemento por cada\n",
    "    # matricula detectada\n",
    "    input_images, _ = load(directory)\n",
    "    # Lo mismo en color\n",
    "    input_images_color, _ = load(directory, color=True)\n",
    "    # Lista de coordenadas de las matriculas. Cada array tiene tantas filas como matriculas hay en la imagen\n",
    "    matriculas = get_contorno_matricula_haar(input_images)\n",
    "\n",
    "    train_images = deteccion_orb.load()\n",
    "    orb = cv.ORB_create(nfeatures=300, scaleFactor=1.3, nlevels=4)\n",
    "    match_table, flann = deteccion_orb.train(train_images, orb)\n",
    "\n",
    "    matriculas_total = []\n",
    "    caracteres = []\n",
    "    \n",
    "    for i in range(len(matriculas)):\n",
    "        if len(matriculas[i]) > 0:\n",
    "            numbers, _ = localizacion_matricula.find_numbers_in_plates(input_images[i], matriculas[i])\n",
    "            rect_plate = matriculas[i]\n",
    "            rect_plate = rect_plate[0]\n",
    "            caracteres.append([numbers])\n",
    "            matriculas_total.append([rect_plate])\n",
    "        else:\n",
    "            detected_points = deteccion_orb.detect([input_images[i]], orb, match_table, flann, 4, 2, 1)\n",
    "            centre = detected_points[0]\n",
    "            rect_plates, box_plates = localizacion_matricula.get_possible_plates(input_images[i], centre)\n",
    "            numbers = localizacion_matricula.find_numbers_in_plates(input_images[i], rect_plates, rotated_plate=True)\n",
    "            for j in range(2, 5):\n",
    "                if len(numbers) < 4:\n",
    "                    rect_plates, box_plates = localizacion_matricula.get_possible_plates(input_images[i], centre,\n",
    "                                                                                         erode=True, esize=j)\n",
    "                    numbers, plate_index = localizacion_matricula.find_numbers_in_plates(input_images[i], rect_plates,\n",
    "                                                                                         rotated_plate=True)\n",
    "            if len(rect_plates) > 0:\n",
    "                rect_plate = rect_plates[plate_index]\n",
    "            caracteres.append([numbers])\n",
    "            matriculas_total.append(np.array([rect_plate]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Una vez que todas las matrículas están detectadas y almacenadas en la variable *matriculas_total*, se recorren esta \n",
    "lista y la que contiene las imágenes originales para recortar la región que pertenece a la matrícula. Este recorte no \n",
    "se realiza en el momento de la localización de los caracteres porque más tarde necesitaremos las coordenadas de estos. \n",
    "Para las matrículas con 8 o más caracteres detectados, cosas que no puede ocurrir, se seleccionan las 7 que \n",
    "corresponden a caracteres en función de la distancia de la altura de los caracteres con respecto a la media de las \n",
    "alturas.\n",
    "\n",
    "La aplicación se ha desarrollado de modo que se permite la detección de varias matrículas por imagen, es por ello que \n",
    "las estructuras de datos contienen listas anidadas. Cada lista tendrá una lista en su interior por cada imagen, y cada \n",
    "una de estas, a su vez, contendrá una lista por cada matrícula detectada, y estas últimas albergarán en ellas las \n",
    "coordenadas de los caracteres de dicha matrícula. También es por esta razón que haya métodos como *get_contornos()* o \n",
    "*get_contornos_lista()*. La primera función está enfocada a la detección de una sola matrícula por imágen, mientras \n",
    "que la segunda soporta varias y hace uso de la primera.\n",
    "\n",
    "Por último, los caracteres son recortados de las imágenes originales, umbralizados e invertidos. La función devuelve \n",
    "estas últimas imágenes con los caracteres recortados y las coordenadas de las matrículas y dichos caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de regiones de las imagenes conteniendo las matriculas\n",
    "    roi_matricula = []\n",
    "    for (img, mat) in zip(input_images, matriculas_total):\n",
    "        aux = []\n",
    "        for (x, y, w, h) in mat:\n",
    "            aux.append(img[y:y + h, x:x + w])\n",
    "        roi_matricula.append(aux)\n",
    "\n",
    "    # De todos los caracteres queremos obtener 7, ya que tambien detecta la E y las sobras de izquierda y derecha\n",
    "    caracteristicas_seleccionadas = []\n",
    "    for coche in caracteres:\n",
    "        aux_coche = []\n",
    "        for matricula in coche:\n",
    "            aux_matricula = []\n",
    "            medias = []\n",
    "            for (x, y, w, h) in matricula:\n",
    "                medias.append((h, (x, y, w, h)))\n",
    "\n",
    "            if (len(medias) < 8):\n",
    "                for (_, (x, y, w, h)) in medias:\n",
    "                    aux_matricula.append((x, y, w, h))\n",
    "            else:\n",
    "                mean_y = 0\n",
    "                for (y, _) in medias:\n",
    "                    mean_y += y\n",
    "                mean_y = mean_y / len(medias)\n",
    "\n",
    "                medias.sort(key=lambda r: np.abs(r[0] - mean_y))\n",
    "                for (_, (x, y, w, h)) in medias[:7]:\n",
    "                    aux_matricula.append((x, y, w, h))\n",
    "\n",
    "            aux_matricula.sort(key=coordenada_x)\n",
    "            aux_coche.append(aux_matricula)\n",
    "\n",
    "        caracteristicas_seleccionadas.append(aux_coche)\n",
    "\n",
    "    # Obtiene las secciones de imagen con los caracteres\n",
    "    roi_caracteres = []\n",
    "    for (image_list, coche) in zip(roi_matricula, caracteristicas_seleccionadas):\n",
    "        aux = []\n",
    "        for (image, mat) in zip(image_list, coche):\n",
    "            aux.append([image[y:y + h, x:x + w] for (x, y, w, h) in mat])\n",
    "        roi_caracteres.append(aux)\n",
    "\n",
    "    # Las vuelve a unmbralizar e invertir\n",
    "    roi_caracteres_umbral = []\n",
    "    for li in range(len(roi_caracteres)):\n",
    "        roi_caracteres_umbral.append(umbralizado_lista(roi_caracteres[li], False, 2))\n",
    "\n",
    "    roi_caracteres_umbral_inv = []\n",
    "    for li in roi_caracteres_umbral:\n",
    "        roi_caracteres_umbral_inv.append(negativo(li))\n",
    "\n",
    "    return roi_caracteres_umbral_inv, matriculas_total, caracteristicas_seleccionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Apartado 2: Reconocimiento de los caracteres localizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este apartado aparece desarrollado en el fichero *reconocimiento_caracteres.py*. Al principio de este se importan las \n",
    "librerías a utilizar y el fichero *localizacion_caracteres* desarollado en el apartado anterior.\n",
    "\n",
    "`os` permite la obtención de los archivos que se encuentran en un directorio para ser cargados posteriormente mediante \n",
    "`cv2`; `numpy` servirá para la creación de matrices multidimensionales; y las clases `LinearDiscriminantAnalysis` y \n",
    "`GaussianNB` de `sklearn` permitirán la reducción de la dimensionalidad de las matrices y la clasificación de los \n",
    "caracteres localizados, respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import localizacion_caracteres as localizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se definen los siguientes métodos:\n",
    "\n",
    "El método `get_chars_countour()`recibe una lista de imágenes como parámetro. Para cada imagen, localiza las compomentes \n",
    "conexas mediante la llamada a la función `cv.findContours()`. Esta función recibe como parámetro:\n",
    "\n",
    "- **image**: la imagen umbralizada sobre la que localizar las componentes conexas. La imagen debe tener un solo canal \n",
    "y los contornos a detectar deben tener un valor distinto de 0, ya que los 0s se toman como fondo y los mayores \n",
    "que 0 (tomados como 1s), son los que se detectan. \n",
    "- **mode**: especifica los contornos a devolver. Se necesitan todos los contornos sin establecer relaciones de jerarquía \n",
    ", por lo que se pasa `cv.RETR_LIST`.\n",
    "- **method**: especifica el método de aproximación de los contornos. Ya que se busca obtener todos los puntos sin \n",
    "aproximación, se pasa `cv.CHAIN_APPROX_NONE`.\n",
    "\n",
    "La función devuelve los contornos de las componentes conexas encontradas en la imagen (variable *contour*) y la \n",
    "jerarquía de los puntos. Ya que no se han establecido relaciones, no es necesario almacenar esta información. Para cada \n",
    "componente conexa encontrada, se obtiene el recuadro que rodea el contorno de esta llamando a la función \n",
    "`cv.boundingRect()` y pasando como argumento el contorno. Para cada imagen se obtendrá una lista con el rectángulo que \n",
    "rodea la región de interés, y esta lista se almacenará en otra con el resto de recuadros del resto de imágenes. La lista \n",
    "devuelta contendrá, a su vez, una lista por cada imagen, conteniendo los recuadros de los contornos de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_chars_countour(images):\n",
    "    \"\"\"Devuelve una lista con tantas listas como imagenes, cada una de estas conteniendo los caracteres encontrados\n",
    "    en cada imagen\"\"\"\n",
    "    char_contour = []\n",
    "    for image in images:\n",
    "        aux = []\n",
    "        contour, _ = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "        for cnt in contour:\n",
    "            x, y, w, h = cv.boundingRect(cnt)\n",
    "            aux.append((x, y, w, h))\n",
    "        char_contour.append(aux)\n",
    "\n",
    "    return char_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función, *get_chars_image()* recibe una lista de imágenes y las coordenadas de la posicion de los \n",
    "contornos detectados en estas y devuelve una lista de imágenes con la region del contorno recortado.\n",
    "\n",
    "- **images**: lista de imágenes.\n",
    "- **characters**: lista con tantas listas como imágenes, donde cada una de estas contiene la posición de los \n",
    "recuadros que contienen los contornos detectados.\n",
    "- **cont**: array de *Numpy* con una fila y tantas columas como posibles clases se pueden detectar.\n",
    "\n",
    "Se empareja cada imagen y su lista de contornos detectados correspondiente y se ordenan los recuadros por área \n",
    "descendiente. Esto se debe a que a veces se detectan dos contornos, uno con la región deseada, y otro con una sección \n",
    "interna de este que no interesa. Se obtiene el primer contorno, el que engloba toda la región de interés y se añade a \n",
    "la lista. Además, se incrementa el contador de la clase del contorno detectado. Devuelve una lista con el recorte de la \n",
    "imagen original donde aparece la componente conexa localizada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_chars_image(images, characters, cont):\n",
    "    \"\"\"Devuelve una lista con los caracteres detectados en la lista, y un contador que indica cuantas muestras hay de\n",
    "    cada letra o numero\"\"\"\n",
    "    chars_images = []\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        chars = characters[i]\n",
    "        chars.sort(key=area, reverse=True)\n",
    "        if len(chars) > 0:\n",
    "            (x, y, w, h) = chars[0]\n",
    "            chars_images.append(image[y:y + h, x:x + w])\n",
    "            cont[i // 250] += 1\n",
    "\n",
    "    return chars_images, cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última función `area()` recibe un contorno y devuelve el área de este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def area(contour):\n",
    "    \"\"\"Devuelve el area de un rectangulo\"\"\"\n",
    "    return contour[2] * contour[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define la clase `ReconocimientoCaracteres`. El constructor recibe lo siguiente:\n",
    "\n",
    "- **included_characters**: lista con los caracteres con los que se va a entrenar el clasificador.\n",
    "- **directory**: directorio en el que se encuentran las imágenes que se van a usar para entrenar el clasificador.\n",
    "\n",
    "Almacena los valores recibidos y crea un *LDA* y un clasificador de Bayes gausiano.\n",
    "\n",
    "EL método *__load()* es privado y su función es cargar en una lista las imágenes que corresponden a los caracteres \n",
    "contenidos en *included_characters*. El nombre de los ficheros de imagen empieza con el caracter en cuestión, por lo \n",
    "que, de los archivos obtenidos mediante `os.scandir()`, solamente se incluyen los archivos cuyo nombre empieza por\n",
    "alguna de las letras incluidas en la lista. Se obtiene una lista con las rutas de las imágenes y se ordenan. El \n",
    "método recibe dos argumentos opcionales, un *boolean* que especifica si se desea la imagen en color o no y otro que \n",
    "especifica si se deben invertir las imágenes cargadas. Para la carga de las imágenes se emplea el método `cv.imread()`, \n",
    "que recibe la ruta de la imagen a leer y, opcionalmente, el índice del canal a cargar (se cargan todos por omisión). \n",
    "Para invertir las imágenes se usa la función `cv.bitwise()`, que recibe una imagen e intercambia el valor del píxel por \n",
    "el valor de restar a 255 el valor actual. De este modo, los contornos de interés se procesarán mas adelante como 1s.\n",
    "\n",
    "El método *train()* corresponde a la fase de entrenamiento del LDA y el GNB. Primero carga las imágenes mediante \n",
    " ` __load()`y a continuación le aplica el umbralizado con el método `threshold()` del módulo `localizacion`.\n",
    "  En el umbralizado no aplica difuminado sobre la imagen y emplea el método de Otsu. La lista \n",
    "obtenida contiene las imágenes con dos valores de píxel, 0 y 255. Ya que se aplicó un filtro de negativo a las imágenes \n",
    "en la carga, los caracteres estarán a 255 y, el fondo, a 0. Las imágenes obtenidas se pasan a `get_chars_contour()` \n",
    "para encontrar las coordenadas de los recuadros que abarcan el contorno de los caracteres. La variable `cont` es una \n",
    "matriz de ceros con una fila y tantas columnas como posibles caracteres hay que detectar. El método `get_chars_image()` \n",
    "recibe la lista inicial de imágenes cargadas, las coordenadas de los caracteres localizados en estas imágenes y esta \n",
    "última variable `cont`, que servirá para contar cuántas muestras hay de cada caracter. La función devuelve una lista \n",
    "con tantas listas como imágenes hay, cada lista de estas conteniendo un recorte de la imagen original conteniendo los \n",
    "caracteres detectados; y el contador actualizado. Estas imágenes con los caracteres son sometidas a un cambio de tamaño. \n",
    "De esto se encarga el método `cv.resize()`. Este recibe como argumento cada una de las imágenes de los caracteres, el \n",
    "tamaño final deseado, en este caso una tupla (10, 10) para que pase a tener un tamaño de 10x10 píxeles; y el método de \n",
    "interpolación, en este caso `cv.INTER_LINEAR` para realizar una interpolación bilineal. Reorganizando las filas de la \n",
    "matriz que representa la imagen en una fila de 100 columnas y disponiendo cada imagen de entrenamiento como una fila de \n",
    "la matriz se obtiene la matriz C, el vector de características. De la variable `cont` se obtiene la matriz E, que \n",
    "indica a qué clase pertenece cada \n",
    "fila de la matriz, es decir, cada imagen. Con estas dos matrices y el método `fit()` se entrena el LDA y mediante \n",
    "`transform()` se reduce el vector de características. Y es con este último el que sirve para entrenar finalmente el \n",
    "clasificador bayesiano.\n",
    "\n",
    "Por último, el método `detect()` recibe una matriz D similar a C y que será el vector de características de los \n",
    "caracteres a reconocer. Se reduce la dimensionalidad de la matriz D mediante en LDA del mismo modo y se devuelve una \n",
    "matriz con tantas columnas como elementos reconocidos, conteniendo cada una de estas el índice de la matriz de \n",
    "caracteres incluidos que corresponde al caracter reconocido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReconocimientoCaracteres:\n",
    "    \"\"\"Reconocedor de caracteres en matriculas mediante LDA y GNB\"\"\"\n",
    "\n",
    "    def __init__(self, included_characters, directory):\n",
    "        \"\"\"Crea un LDA y un GNB para el reconocimiento de caracteres\"\"\"\n",
    "        self.included_characters = included_characters\n",
    "        self.images_directory = directory\n",
    "        self.lda = LinearDiscriminantAnalysis()\n",
    "        self.gnb = GaussianNB()\n",
    "\n",
    "    def __load(self, color=False, invert=True):\n",
    "        \"\"\"Devuelve una lista con las imagenes contenidas en el directorio de imagenes\"\"\"\n",
    "        cur_dir = os.path.abspath(os.curdir)\n",
    "        with os.scandir(cur_dir + '/' + self.images_directory) as it:\n",
    "            files = [file.name for file in it if file.name[0] in self.included_characters and file.is_file()]\n",
    "        it.close()\n",
    "        files.sort()\n",
    "        if color is True:\n",
    "            return [cv.imread(self.images_directory + '/' + file) for file in files]\n",
    "        else:\n",
    "            if invert is True:\n",
    "                return [cv.bitwise_not(cv.imread(self.images_directory + '/' + file, 0)) for file in files]\n",
    "            else:\n",
    "                return [cv.imread(self.images_directory + '/' + file, 0) for file in files]\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Entrena un clasificador Naive Bayes para la deteccion de caracteres\"\"\"\n",
    "        input_images = self.__load()\n",
    "        input_images_threshold = localizacion.threshold(input_images, False, 2)\n",
    "        input_chars = get_chars_countour(input_images_threshold)\n",
    "\n",
    "        cont = np.zeros((len(self.included_characters)), dtype=np.uint16)\n",
    "        roi_input_chars, cont = get_chars_image(input_images, input_chars, cont)\n",
    "\n",
    "        roi_chars_resized = [cv.resize(image, (10, 10), 0, 0, cv.INTER_LINEAR) for image in roi_input_chars]\n",
    "\n",
    "        C = np.array([char.reshape(1, 100).astype(np.float64) for char in roi_chars_resized])[:, 0, :]\n",
    "        E = [i for i in range(cont.shape[0]) for _ in range(cont[i])]\n",
    "\n",
    "        self.lda.fit(C, E)\n",
    "        CR = self.lda.transform(C)\n",
    "        self.gnb.fit(CR, E)\n",
    "\n",
    "        return C, E\n",
    "\n",
    "    def detect(self, D):\n",
    "        \"\"\"Reconoce los caracteres de la matriz D\"\"\"\n",
    "        DR = self.lda.transform(D)\n",
    "        return self.gnb.predict(DR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3: Integración de todos los algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el fichero *leer_coche.py* realizamos algunas operaciones básicas como cargar las imágenes, controlar la llamada\n",
    "al programa, mostrar las imágenes finales si es requerido y crear el fichero de texto con las matrículas reconocidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *get_name()* elimina la parte de la ruta que no es el fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_name(path):\n",
    "    if path.find('/') != -1:\n",
    "        filename = path[path.find('/'):]\n",
    "    elif path.find('\\\\') != -1:\n",
    "        filename = path[path.find('\\\\'):]\n",
    "    else:\n",
    "        filename = path\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casi todo esto se integra en el método *leer()*, así que vamos a verlo por partes.\n",
    "\n",
    "Primero cargamos las imágenes en color y almacenamos los nombres de las imágenes. Tras esto abrimos un fichero de texto\n",
    " en el que se volcarán las matrículas detectadas y creamos los conjuntos de letras y números cuya unión resulta en el\n",
    " conjunto de carácteres posibles en una matrícula española.\n",
    "\n",
    "Al final de este fragmento inicializamos y entrenamos dos clasificadores, uno de números y otro de letras consonantes.\n",
    " Esto nos sirve para minimizar posibles errores al clasificar por ejemplo una __D__ como un **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def leer(directorio, visualizar):\n",
    "    input_images_color, nombre_imagenes = localizacion.load(directorio, color=True)\n",
    "\n",
    "    filename = get_name(directorio) + '.txt'\n",
    "    file = open(filename, 'w')\n",
    "\n",
    "    numbers = [str(n) for n in list(range(10))]\n",
    "    letters = string.ascii_uppercase\n",
    "    valid_letters = [c for c in\n",
    "                     letters.replace('A', '').replace('E', '').replace('I', '').replace('O', '').replace('U', '')]\n",
    "\n",
    "    numeros = ReconocimientoCaracteres(numbers, 'training_ocr')\n",
    "    C, E = numeros.entrenar()\n",
    "    # numeros.test(C)\n",
    "\n",
    "    letras = ReconocimientoCaracteres(valid_letters, 'training_ocr')\n",
    "    C, E = letras.entrenar()\n",
    "    # letras.test(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos una llamada al método que busca las matrículas y los carácteres que se encuentran dentro de ellas sobre todas las imágenes del directorio especificado. En la variable *local* se guarda un array por cada imagen que contiene un array de arrays con los carácteres encontrados en cada matrícula de esa imagen. Para cada uno de estos carácteres vamos a redimensionar la imagen que lo contiene y cambiar la forma del array para obtener un vector con 100 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local, matriculas, caracteres = localizacion.localizar(directorio)\n",
    "\n",
    "    local_resized = []\n",
    "    for image_list in local:\n",
    "        aux = []\n",
    "        for image in image_list:\n",
    "            aux.append(\n",
    "                [cv.resize(char, (10, 10), 0, 0, cv.INTER_LINEAR).reshape(1, 100).astype(np.float64) for char in image])\n",
    "        local_resized.append(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como último paso, se recorren los caracteres y las matrículas localizadas, construyendo la matriz F, que corresponde\n",
    "al vector de características de los caracteres a detectar. Se dispone de un clasificador para letras y otra para\n",
    "números, y nos basamos en el indice de la posición del caracter para clasificar mediente uno u otro.\n",
    "Datos como la posición de la matrícula y los caracteres encontrados se almacenan en un fichero y, si se ha pasado el\n",
    "parámetro 'True' en la llamada al programa, se muestran las imágenes por pantalla con los caracteres detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for img in range(len(local_resized)):\n",
    "        imagen = input_images_color[img]\n",
    "        for m in range(len(local_resized[img])):\n",
    "            if len(local_resized[img][0]) > 0:\n",
    "                F = np.array([char for char in local_resized[img][m]])[:, 0, :]\n",
    "                out_numeros = numeros.reconocer(F[:4])\n",
    "                out_letras = [letras.included_characters[i] for i in letras.reconocer(F[-3:])]\n",
    "                texto_matricula_numeros = str(out_numeros[0]) + str(out_numeros[1]) + str(out_numeros[2]) \\\n",
    "                                          + str(out_numeros[3])\n",
    "                texto_matricula_letras = str(out_letras[0]) + str(out_letras[1]) + str(out_letras[2])\n",
    "\n",
    "                (x, y, w, h) = matriculas[img][m]\n",
    "\n",
    "                nombre_imagen = get_name(nombre_imagenes[img])\n",
    "                x_centro_matricula = x + w // 2\n",
    "                y_centro_matricula = y + h // 2\n",
    "                texto_matricula = texto_matricula_numeros + ' ' + texto_matricula_letras\n",
    "                mitad_largo_matricula = w // 2\n",
    "                file.write(str(nombre_imagen) + ' ' + str(x_centro_matricula) + ' ' + str(y_centro_matricula) + ' ' +\n",
    "                           texto_matricula + ' ' + str(mitad_largo_matricula) + '\\n')\n",
    "\n",
    "                imagen = cv.rectangle(imagen, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                imagen = cv.circle(imagen, (x_centro_matricula, y_centro_matricula), 5, (0, 255, 0), thickness=2,\n",
    "                                   lineType=8, shift=0)\n",
    "\n",
    "                matricula = caracteres[img][m]\n",
    "                caracteres_matricula = texto_matricula.replace(' ', '')\n",
    "                for i in range(len(matricula)):\n",
    "                    (a, b, c, d) = matricula[i]\n",
    "                    imagen = cv.rectangle(imagen, (x+a, y+b), (x+a + c, y+b + d), (0, 0, 255), 1)\n",
    "                    imagen = cv.putText(imagen, caracteres_matricula[i], (x+a,y+b), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1, (255, 0, 0), 1, cv.LINE_AA)\n",
    "\n",
    "        if visualizar:\n",
    "            plt.imshow(cv.cvtColor(imagen, cv.COLOR_RGB2BGR))\n",
    "            plt.show()\n",
    "            pass\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último fragmento corresponde a la ejecución de todos los métodos cuando se invoca la aplicación en una terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    assert len(sys.argv) > 1, \\\n",
    "        \"Debes introducir al menos un argumento, el directorio donde se encuentran las imagenes.\\n\" \\\n",
    "        \"Uso: python leer_coche.py <path_completo_directorio_coches> [<visualizar_resultados>] \\n\" \\\n",
    "        \"El parametro entre corchetes es opcional y su valor por defecto es 'False'.\"\n",
    "\n",
    "    if len(sys.argv) > 2:\n",
    "        visualizar_resultados = sys.argv[2]\n",
    "    else:\n",
    "        visualizar_resultados = False\n",
    "    directorio_imagenes = sys.argv[1]\n",
    "\n",
    "    leer(directorio_imagenes, visualizar_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apartado 4: Ejecución\n",
    "\n",
    "La práctica deberá ejecutarse sobre Python 3.7.X y OpenCV 4.3 mediante el siguiente mandato:\n",
    "\n",
    "<code>>$ python leer_coche.py [directorio de imágenes de testing] [visualización de imágenes por pantalla]</code>\n",
    "donde los argumentos son los siguientes:\n",
    "\n",
    "-   *directorio de imágenes de testing*: Ruta relativa del directorio que contiene las imágenes de testing.\n",
    "\n",
    "-   *visualización de imágenes por pantalla*: Puede tomar los valores *True* o *False*.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}